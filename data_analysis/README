Analyzing cachenice datafiles
-----------------------------

This directory contains a few scripts that are useful for interpreting experimental results:
 - pres_graphs: for generating graphs of lockserver runs
 - mica2_tables: for computing tail latencies and computing (optionally normalized) performance counters of Mica runs
   (although this *can* be used on lockserver runs: see the section near the bottom)
 - timescale_and_cdf: for generating timescales and CDFs of lockserver runs
 - largescale_and_cdf: variant of above for use with Mica runs; reads points from -us.log list instead of JSON


Running pres_graphs on a lockserver run
=======================================
This script generates a number of graphs.
It expects, minimally, the datafile for a run recording the effect of varying the number of table entries;
however, you can also pass it (as the middle argument) an additional datafile from a run that varies the delay between requests.
In the latter case, it will generate some additional graphs.
Imagine we have a datafile cerberus_8contenders-trashslowdown.json,
generated by running the experiment on the cachenice_trashslowdown branch using: $ ./network_rtt -t wimpy catbench <MAC>

 $ ./pres_graphs cerberus_8contenders-trashslowdown.json lockserver8.json

The last filename should be available: the files created by the script will be named based on it.
There will be some debugging output and a few syntax errors output, but you should be able to ignore all that.

NB: You'll only get graphs of the contenders' throughputs if you run the script on the cachenice_trashslowdown branch.


Running timescale_and_cdf on a lockserver run
=============================================
To get the timescales and CDFs, you need to start with a raw JSON, as generated by the network_rawnums script.
(The pres_graphs script does this for you.)
Assuming we have a raw JSON named lockserver8-raw.json, we do:

 $ ./timescale_and_cdf lockserver8 jaguar/jaguar make-cdf

Notice how the -raw.json suffix is excluded in the command-line argument; the output will be in a new folder called lockserver8.

NB: Unlike with largescale_and_cdf, the resulting plots *include* the warmup interval.


Lockserver runs with a different number of contenders
=====================================================
If you have any number of contenders other than 8, you need to modify the CONTENDERS variable at the top of the pres_graphs script.
Then use it normally, as described above.


Running mica2_tables on a Mica Zipf run
=======================================
By default, the script is set up to operate on runs varying the Zipf alpha parameter.
To run it on the results from an experiment with different parameters, you need to tweak some of the contants at the top;
this process is described in another section below.
Here's an example of how to run it on a datafile cerberus_15contenders-mica2.json,
generated by running the experiment on the cachenice_mica2 branch using: $ ./network_rtt -t wimpy catbench

 $ ./mica2_tables -u -a -t -e -n cerberus_15contenders-mica2.json | tee cerberus_15contenders-mica2.json

This will output the following tables to stdout and a text file:
 - [-a switch] Average latencies (extracted directly from the JSON)
 - [-t switch] 99.9% latencies (computed from entries scraped from the execution log)
 - [-e switch] Performance event counters (scraped from the execution log)
 - [-n switch] Performance event counters normalized to execution time (computed from execution log scrape)

Note that your run must record the elapsed times (appear as "seconds time elapsed" in the log) in order to use the -n switch;
some older experiments didn't measure this information, so normalization is impossible.

Running the script will automatically extract the experiment log to a file called cerberus_15contenders-mica2.log,
decompressing it if necessary (as specified by the meta.unpack field).
Note that, if a file with this name is already present in the current directory,
the script will attempt to save time by instead reading the log directly from that.

Worth noting is the -u switch, which doesn't result in any additional output;
rather, it extracts the individual latency measurements and saves them to a file called cerberus_15contenders-mica2-us.log.
Analogously to the experiment log optimization described above, the -t option will attempt to reuse such a file if one exists,
rather than reprocessing the entire experiment log in search of these numbers.
Note that this output file is necessary for plotting timescales and CDFs for this type of run.

The -p switch is similar to the -u switch, except it saves the performance counter data scraped from the log.
No other script currently requires *this* information, however.


Running largescale_and_cdf on a Mica Zipf run
=============================================
Again, this script is set up to operate on runs varying the Zipf factor, and must be tweaked as described below in the case of other datafiles.
In order to use it at all, you need a file containing all the latency points in microseconds ("us file").
Such a file can be generated by using the -u switch to mica2_tables, similar to the invocation in the previous section.

Let's assume we already have a us file named cerberus_15contenders-mica2-us.json.
Now we need to run this command to get our timescales and CDFs:

 $ ./largescale_and_cdf cerberus_15contenders-mica2-us jaguar/jaguar make-cdf

Note the absence of the .log at the end of the filename: the script assumes the corresponding .log file exists,
and creates a new directory with the name specified on the command line to house the generated graphs.
In the process, a bunch of error output will be generated, but you can probably ignore it.

NB: Unlike with timescale_and_cdf, the resulting plots *exclude* the warmup interval.


Mica runs having different series, varying something other than Zipf, or using a different set of independent values
====================================================================================================================
Modify the block of constants at the top of the mica2_tables script before running it:
 - SERIES is a space-separated list of the data series.
 - DEP is the dependent variable.
 - INDEPS are the (space-separated) values assigned to the independent variable, in the order of their execution in the experiment.
 - ITERATIONS is the number of individual samples logged per datapoint.
 - WARMUP is the number of samples that should be dropped from the beginning of each series/independent pair.

For example, imagine we have a sensitivity analysis run we want to analyze.
It's in a file named cerberus_zipf99-sensitivity.json, and was generated using: ./network_rtt -m wimpy catbench

We modify the variables as follows:
 - Change INDEPS to "0x007 0x00f 0x01f 0x03f 0x07f 0x0ff 0x1ff 0x3ff" (DEFAULT_MICA_WAYS_LOOP from network_rtt)

Then run the script normally:

 $ ./mica2_tables -u -a -t -e -n cerberus_zipf99-sensitivity.json | tee cerberus_zipf99-sensitivity.txt

Because we included the -u above, we can now get timescale plots and CDFs as well if we'd like...

Modify the largescale_and_cdf script to generate the right number of plots:
 - Change INDICES to "`seq 0 7`" to match the *8* series in the other script's INDEPS variable.
 - Update the SERIES variable if necessary.
 - Look for the lines beginning with "$name$suffix/data_`... near the end of the script. Make sure there's one for each word in the SERIES variable.  (Be sure to also update the indices passed to cut, which are one-based.)

Run that script normally as well.


Running mica2_tables on a lockserver run
========================================
This is possible by following a similar procedure to that described in the previous section.  In particular:
 - You're likely to have to modify the SERIES constant to remove basealloc.
 - Only the -a and -t switches will work if there's no performance counter data recorded.
 - You can use -u if you want, but are mainly expected to graph using timescale_and_cdf...


Running largescale_and_cdf with a different number of samples or a different warmup period
==========================================================================================
This information is hardcoded in the script: search for a lot of consecutive zeroes.  Sorry about that!
